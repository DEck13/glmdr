
\documentclass[11pt]{article}

\usepackage{indentfirst}
\usepackage{natbib}
\usepackage{url}

\newcommand{\REVISED}{\begin{center}\LARGE REVISED DOWN TO HERE\end{center}}

%\VignetteEngine{knitr::knitr}

\begin{document}

\title{Design Document for GLMDR Package}

\author{Charles J. Geyer}

\maketitle

\section{Introduction}

We implement the stuff in \citet{geyer-gdor} and \citet{eck-geyer},
fixing it where necessary.
We start with an R function just like the R function \texttt{glm} in
the R core, except for the following differences
\begin{itemize}
\item It does solutions at infinity right!
\item It only does exponential family models.  No quasi-likelihood.
    No non-canonical link functions.  No non-discrete distributions.
    That leaves only \texttt{binomial("logit")} and \texttt{poisson("log")}
    of the families allowed for the R function \texttt{glm}.
\item We might also want to do zero-inflated Poisson regression using
    the aster parameterization \citep*{geyer-wagenius-shaw}
    so it is exponential family too.
    But ignore this for the first version.  It would complicate things
    to allow aster graph models, even one this simple.
\item We certainly want to do multinomial and product multinomial response.
    Unlike the approaches of the R functions \texttt{multinom} in the R
    recommended packages \texttt{mgcv}
    and \texttt{nnet}, we don't need a special function to fit these
    models.

    As is well known \citep[Section~8.6.7]{agresti}, the 
    maximum likelihood estimator (MLE) of the mean value parameter
    vector is the same whether the sampling scheme is Poisson,
    multinomial or product multinomial.  As is not so well known
    \citep[Section~3.17]{geyer-gdor} the MLE for the canonical parameter
    vector is also the same, when we use the same parameterization for all
    three models.  Then the MLE for Poisson is unique (if the model matrix
    has full column rank) but the MLE for multinomial or product multinomial
    will not be unique, but the unique MLE for Poisson is also a (non-unique)
    MLE for multinomial or product multinomial.

\item We do need a special argument for the function that makes one-sided
    confidence intervals when solutions at infinity exist, because these
    are non-asymptotic and depend on the exact sampling distribution
    \citep[Sections~3.16 and~3.17]{geyer-gdor}.

    Since multinomial and product multinomial models
    can be derived from Poisson models by conditioning on the sum
    of the response vector (multinomial) or on the sums of components
    of the response vector over elements of a partition of its index set
    (product multinomial), in our confidence interval function or functions
    we just have an argument that describes such conditioning (if wanted).

\end{itemize}

<<options-width,include=FALSE,echo=FALSE>>=
options(keep.source = TRUE, width = 60)
@

The R core has the following methods for objects of class \texttt{"glm"}
as of this writing.
<<methods>>=
R.Version()$version.string
.S3methods(class = "glm")
.S4methods(class = "glm")
@
Some of these methods make no sense for the models fit by this package
(described above)
We definitely need methods for
\begin{verbatim}
anova
confint
predict
summary
print.summary
\end{verbatim}
We may consider others later.

\section{Model Fitting Function}

\subsection{Signature}

The signature for the R function \texttt{glm} is
<<signature-glm>>=
args(glm)
@

Some of these arguments have no use for the kind of models fit by this
package or are so seldom used that we can omit them.  We start with the
following signature.
\begin{verbatim}
glmdr(formula, family = c("binomial", "poisson"), data,
    subset, na.action, offset, contrasts = NULL)
\end{verbatim}

\subsection{Initial Fit}

Our function then immediately calls R function \texttt{stats::glm} with
the same arguments (using \texttt{match.call} and \texttt{eval}) except
we add the argument \verb@x = TRUE@ so that we get the model matrix.

\subsection{Polish Fit}

We don't trust that the computer arithmetic in R function \texttt{glm}
is careful enough to really push the accuracy.  So we implement our
own algorithm to maximize the likelihood some more.  Since the solution
may be at infinity, we do Newton iterations safeguarded by line search,
terminating the line search so that all of our steps are uphill.

We also implement a function that calculates the log likelihood and two
derivatives very carefully, to avoid overflow and catastrophic cancellation.

\subsection{Polishing}

\begin{thebibliography}{}

\bibitem[Agresti(2013)]{agresti}
Agresti, A. (2013).
\newblock \emph{Categorical Data Analysis}, third edition.
\newblock John Wiley \& Sons, Hoboken, NJ.

\bibitem[Geyer(2009)]{geyer-gdor}
Geyer, Charles J. (2009).
\newblock Likelihood inference in exponential families and directions
    of recession.
\newblock \emph{Electronic Journal of Statistics}, \textbf{3}, 259--289.

\bibitem[Geyer, et~al.(2007)Geyer, Wagenius, and Shaw]{geyer-wagenius-shaw}
Geyer, C.~J., Wagenius, S., and Shaw, R.~G. (2007).
\newblock Aster models for life history analysis.
\newblock \emph{Biometrika}, \textbf{94}, 415--426.

\bibitem[Eck and Geyer(submitted)]{eck-geyer}
Eck, D.~J. and Geyer, C.~J. (submitted).
\newblock Computationally efficient likelihood inference
    in exponential families when the maximum likelihood estimator
    does not exist.
\newblock \url{https://arxiv.org/abs/1803.11240}.

\end{thebibliography}

\end{document}

